#!/usr/bin/env python3
"""
å¹‚ç­‰æ€§å’Œç›‘æ§å‹åŠ›æµ‹è¯•è„šæœ¬
ä¸“é—¨æµ‹è¯•å¹‚ç­‰æ€§æœºåˆ¶å’Œç›‘æ§æŒ‡æ ‡åœ¨é«˜è´Ÿè½½æ¡ä»¶ä¸‹çš„æ€§èƒ½è¡¨ç°
"""

import os
import sys
import json
import time
import hmac
import asyncio
import aiohttp
import hashlib
import argparse
import statistics
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple, Optional
import requests
from dataclasses import dataclass
from collections import defaultdict
import threading

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœæ•°æ®ç±»"""
    timestamp: datetime
    duration: float
    status_code: int
    success: bool
    error: Optional[str] = None
    duplicate_detected: bool = False
    metrics_recorded: bool = False
    response_size: int = 0
    

class IdempotencyMonitoringStressTester:
    """å¹‚ç­‰æ€§å’Œç›‘æ§å‹åŠ›æµ‹è¯•å™¨"""
    
    def __init__(self, base_url: str, webhook_secret: str = "test-secret"):
        self.base_url = base_url.rstrip('/')
        self.webhook_secret = webhook_secret
        self.results: List[TestResult] = []
        self.metrics_cache: Dict[str, Any] = {}
        self.lock = threading.Lock()
        
        # æµ‹è¯•é…ç½®
        self.test_config = {
            "max_concurrent": 50,
            "total_requests": 1000,
            "duplicate_rate": 0.3,  # 30%çš„è¯·æ±‚ä¸ºé‡å¤è¯·æ±‚
            "timeout": 30,
            "metrics_check_interval": 5
        }
    
    def generate_webhook_signature(self, payload: str) -> str:
        """ç”Ÿæˆ webhook ç­¾å"""
        signature = hmac.new(
            self.webhook_secret.encode(),
            payload.encode(),
            hashlib.sha256
        ).hexdigest()
        return signature  # Giteeä½¿ç”¨åŸå§‹hex digestï¼Œä¸éœ€è¦sha256=å‰ç¼€
    
    def create_test_payload(self, test_id: int, is_duplicate: bool = False) -> Dict[str, Any]:
        """åˆ›å»ºæµ‹è¯•ç”¨çš„ payload"""
        # å¦‚æœæ˜¯é‡å¤è¯·æ±‚ï¼Œä½¿ç”¨å›ºå®šçš„å†…å®¹æ¥ç¡®ä¿çœŸæ­£çš„é‡å¤
        if is_duplicate:
            issue_id = 1  # å›ºå®šID
            timestamp = "2024-01-01T00:00:00Z"  # å›ºå®šæ—¶é—´æˆ³
            body_content = "This is a duplicate stress test issue for idempotency testing."
        else:
            issue_id = test_id
            timestamp = datetime.now().isoformat() + "Z"
            body_content = f"This is a stress test issue for idempotency testing. Test ID: {test_id}"
        
        return {
            "action": "opened",
            "issue": {
                "id": 1000000 + issue_id,
                "number": issue_id,
                "title": f"Stress Test Issue #{issue_id}",
                "body": body_content,
                "state": "open",
                "created_at": timestamp,
                "updated_at": timestamp,
                "user": {
                    "login": "stress-tester",
                    "id": 99999
                },
                "labels": [
                    {"name": "stress-test"},
                    {"name": "idempotency" if is_duplicate else "unique"}
                ]
            }
        }
    
    async def send_webhook_request(self, session: aiohttp.ClientSession, test_id: int, 
                                   is_duplicate: bool = False) -> TestResult:
        """å‘é€å•ä¸ª webhook è¯·æ±‚"""
        start_time = time.time()
        
        try:
            payload = self.create_test_payload(test_id, is_duplicate)
            payload_str = json.dumps(payload)
            
            # é‡å¤è¯·æ±‚ä½¿ç”¨å›ºå®šçš„delivery_idæ¥è§¦å‘å¹‚ç­‰æ€§æ£€æµ‹
            if is_duplicate:
                delivery_id = "stress-test-duplicate-fixed-id"
            else:
                delivery_id = f"stress-test-{test_id}-unique"
            
            headers = {
                'Content-Type': 'application/json',
                'X-Gitee-Event': 'Issue Hook',
                'X-Gitee-Token': self.generate_webhook_signature(payload_str),
                'X-Gitee-Delivery': delivery_id
            }
            
            async with session.post(
                f"{self.base_url}/gitee_webhook",
                data=payload_str,
                headers=headers,
                timeout=aiohttp.ClientTimeout(total=self.test_config["timeout"])
            ) as response:
                response_text = await response.text()
                duration = time.time() - start_time
                
                return TestResult(
                    timestamp=datetime.now(),
                    duration=duration,
                    status_code=response.status,
                    success=200 <= response.status < 300,
                    duplicate_detected=(
                        "duplicate" in response_text.lower() or 
                        "replay_attack_detected" in response_text.lower() or
                        response.status == 403  # é‡å¤è¯·æ±‚é€šå¸¸è¿”å›403
                    ),
                    response_size=len(response_text)
                )
                
        except Exception as e:
            duration = time.time() - start_time
            return TestResult(
                timestamp=datetime.now(),
                duration=duration,
                status_code=0,
                success=False,
                error=str(e)
            )
    
    async def fetch_metrics(self, session: aiohttp.ClientSession) -> Dict[str, Any]:
        """è·å–ç›‘æ§æŒ‡æ ‡"""
        try:
            async with session.get(f"{self.base_url}/metrics") as response:
                if response.status == 200:
                    metrics_text = await response.text()
                    return self.parse_prometheus_metrics(metrics_text)
                else:
                    return {"error": f"HTTP {response.status}"}
        except Exception as e:
            return {"error": str(e)}
    
    def parse_prometheus_metrics(self, metrics_text: str) -> Dict[str, Any]:
        """è§£æ Prometheus æ ¼å¼çš„æŒ‡æ ‡"""
        metrics = {}
        
        for line in metrics_text.split('\n'):
            line = line.strip()
            if not line or line.startswith('#'):
                continue
                
            try:
                # ç®€å•çš„æŒ‡æ ‡è§£æ
                if ' ' in line:
                    metric_part, value_part = line.rsplit(' ', 1)
                    metrics[metric_part] = float(value_part)
            except (ValueError, IndexError):
                continue
        
        return metrics
    
    async def monitor_metrics(self, session: aiohttp.ClientSession, duration_seconds: int):
        """æŒç»­ç›‘æ§æŒ‡æ ‡"""
        end_time = time.time() + duration_seconds
        metrics_history = []
        
        while time.time() < end_time:
            metrics = await self.fetch_metrics(session)
            if "error" not in metrics:
                metrics_history.append({
                    "timestamp": datetime.now(),
                    "metrics": metrics
                })
            
            await asyncio.sleep(self.test_config["metrics_check_interval"])
        
        return metrics_history
    
    async def run_idempotency_stress_test(self, concurrent_requests: int, 
                                          total_requests: int) -> Dict[str, Any]:
        """è¿è¡Œå¹‚ç­‰æ€§å‹åŠ›æµ‹è¯•"""
        print(f"ğŸš€ å¼€å§‹å¹‚ç­‰æ€§å‹åŠ›æµ‹è¯•: {total_requests} è¯·æ±‚ï¼Œå¹¶å‘æ•°: {concurrent_requests}")
        
        connector = aiohttp.TCPConnector(limit=concurrent_requests * 2)
        async with aiohttp.ClientSession(connector=connector) as session:
            
            # å¯åŠ¨æŒ‡æ ‡ç›‘æ§
            monitor_task = asyncio.create_task(
                self.monitor_metrics(session, duration_seconds=60)
            )
            
            # åˆ›å»ºè¯·æ±‚ä»»åŠ¡
            tasks = []
            for i in range(total_requests):
                is_duplicate = i % int(1 / self.test_config["duplicate_rate"]) == 0
                task = asyncio.create_task(
                    self.send_webhook_request(session, i, is_duplicate)
                )
                tasks.append(task)
                
                # æ§åˆ¶å¹¶å‘æ•°
                if len(tasks) >= concurrent_requests:
                    completed_tasks = await asyncio.gather(*tasks[:concurrent_requests])
                    self.results.extend(completed_tasks)
                    tasks = tasks[concurrent_requests:]
            
            # å¤„ç†å‰©ä½™ä»»åŠ¡
            if tasks:
                completed_tasks = await asyncio.gather(*tasks)
                self.results.extend(completed_tasks)
            
            # ç­‰å¾…ç›‘æ§ç»“æŸ
            metrics_history = await monitor_task
        
        return self.analyze_results(metrics_history)
    
    def analyze_results(self, metrics_history: List[Dict]) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•ç»“æœ"""
        successful_requests = sum(1 for r in self.results if r.success)
        failed_requests = len(self.results) - successful_requests
        duplicate_detected_count = sum(1 for r in self.results if r.duplicate_detected)
        
        durations = [r.duration for r in self.results if r.success]
        
        if durations:
            avg_duration = statistics.mean(durations)
            median_duration = statistics.median(durations)
            p95_duration = sorted(durations)[int(len(durations) * 0.95)]
            p99_duration = sorted(durations)[int(len(durations) * 0.99)]
        else:
            avg_duration = median_duration = p95_duration = p99_duration = 0
        
        # åˆ†ææŒ‡æ ‡
        metrics_analysis = self.analyze_metrics(metrics_history)
        
        # è®¡ç®—é”™è¯¯ç‡
        error_rate = failed_requests / len(self.results) if self.results else 0
        
        # åˆ†æå¹‚ç­‰æ€§è¡¨ç°
        expected_duplicates = int(len(self.results) * self.test_config["duplicate_rate"])
        idempotency_accuracy = duplicate_detected_count / expected_duplicates if expected_duplicates > 0 else 0
        
        return {
            "summary": {
                "total_requests": len(self.results),
                "successful_requests": successful_requests,
                "failed_requests": failed_requests,
                "error_rate": error_rate,
                "duplicate_detected": duplicate_detected_count,
                "expected_duplicates": expected_duplicates,
                "idempotency_accuracy": idempotency_accuracy
            },
            "performance": {
                "avg_response_time": avg_duration,
                "median_response_time": median_duration,
                "p95_response_time": p95_duration,
                "p99_response_time": p99_duration,
                "total_duration": max(r.timestamp for r in self.results) - min(r.timestamp for r in self.results)
            },
            "metrics": metrics_analysis
        }
    
    def analyze_metrics(self, metrics_history: List[Dict]) -> Dict[str, Any]:
        """åˆ†æç›‘æ§æŒ‡æ ‡"""
        if not metrics_history:
            return {"error": "No metrics data collected"}
        
        # æå–å…³é”®æŒ‡æ ‡çš„å˜åŒ–
        key_metrics = [
            "webhook_requests_total",
            "idempotency_checks_total",
            "duplicate_events_total",
            "sync_events_total",
            "webhook_request_duration_seconds"
        ]
        
        metrics_analysis = {}
        
        for metric_name in key_metrics:
            values = []
            for entry in metrics_history:
                for full_metric_name, value in entry["metrics"].items():
                    if metric_name in full_metric_name:
                        values.append(value)
            
            if values:
                metrics_analysis[metric_name] = {
                    "initial": values[0] if values else 0,
                    "final": values[-1] if values else 0,
                    "increase": (values[-1] - values[0]) if len(values) >= 2 else 0,
                    "max": max(values),
                    "avg": statistics.mean(values)
                }
        
        return metrics_analysis
    
    def generate_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        report = []
        report.append("=" * 80)
        report.append("å¹‚ç­‰æ€§å’Œç›‘æ§å‹åŠ›æµ‹è¯•æŠ¥å‘Š")
        report.append("=" * 80)
        report.append(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"æµ‹è¯•ç›®æ ‡: {self.base_url}")
        report.append("")
        
        # æ¦‚è¦ä¿¡æ¯
        summary = results["summary"]
        report.append("ğŸ“Š æµ‹è¯•æ¦‚è¦:")
        report.append(f"  æ€»è¯·æ±‚æ•°: {summary['total_requests']}")
        report.append(f"  æˆåŠŸè¯·æ±‚: {summary['successful_requests']}")
        report.append(f"  å¤±è´¥è¯·æ±‚: {summary['failed_requests']}")
        report.append(f"  é”™è¯¯ç‡: {summary['error_rate']:.2%}")
        report.append(f"  æ£€æµ‹åˆ°é‡å¤äº‹ä»¶: {summary['duplicate_detected']}")
        report.append(f"  é¢„æœŸé‡å¤äº‹ä»¶: {summary['expected_duplicates']}")
        report.append(f"  å¹‚ç­‰æ€§å‡†ç¡®ç‡: {summary['idempotency_accuracy']:.2%}")
        report.append("")
        
        # æ€§èƒ½æŒ‡æ ‡
        perf = results["performance"]
        report.append("âš¡ æ€§èƒ½æŒ‡æ ‡:")
        report.append(f"  å¹³å‡å“åº”æ—¶é—´: {perf['avg_response_time']:.3f}s")
        report.append(f"  ä¸­ä½å“åº”æ—¶é—´: {perf['median_response_time']:.3f}s")
        report.append(f"  95% å“åº”æ—¶é—´: {perf['p95_response_time']:.3f}s")
        report.append(f"  99% å“åº”æ—¶é—´: {perf['p99_response_time']:.3f}s")
        report.append("")
        
        # ç›‘æ§æŒ‡æ ‡åˆ†æ
        metrics = results["metrics"]
        if "error" not in metrics:
            report.append("ğŸ“ˆ ç›‘æ§æŒ‡æ ‡åˆ†æ:")
            for metric_name, data in metrics.items():
                report.append(f"  {metric_name}:")
                report.append(f"    åˆå§‹å€¼: {data['initial']:.2f}")
                report.append(f"    æœ€ç»ˆå€¼: {data['final']:.2f}")
                report.append(f"    å¢é•¿é‡: {data['increase']:.2f}")
                report.append(f"    æœ€å¤§å€¼: {data['max']:.2f}")
                report.append(f"    å¹³å‡å€¼: {data['avg']:.2f}")
        else:
            report.append(f"âŒ ç›‘æ§æŒ‡æ ‡æ”¶é›†å¤±è´¥: {metrics['error']}")
        
        report.append("")
        report.append("=" * 80)
        
        return "\n".join(report)
    
    async def run_comprehensive_test(self):
        """è¿è¡Œç»¼åˆå‹åŠ›æµ‹è¯•"""
        print("ğŸ§ª å¼€å§‹è¿è¡Œå¹‚ç­‰æ€§å’Œç›‘æ§ç»¼åˆå‹åŠ›æµ‹è¯•...")
        
        # æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€
        try:
            response = requests.get(f"{self.base_url}/health", timeout=10)
            if response.status_code != 200:
                print(f"âŒ æœåŠ¡å¥åº·æ£€æŸ¥å¤±è´¥: HTTP {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ æœåŠ¡è¿æ¥å¤±è´¥: {e}")
            return False
        
        print("âœ… æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡")
        
        # è¿è¡Œå‹åŠ›æµ‹è¯•
        results = await self.run_idempotency_stress_test(
            concurrent_requests=self.test_config["max_concurrent"],
            total_requests=self.test_config["total_requests"]
        )
        
        # ç”Ÿæˆå¹¶æ‰“å°æŠ¥å‘Š
        report = self.generate_report(results)
        print(report)
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        report_filename = f"idempotency_monitoring_stress_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ğŸ“‹ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filename}")
        
        # è¯„ä¼°æµ‹è¯•ç»“æœ
        return self.evaluate_test_results(results)
    
    def evaluate_test_results(self, results: Dict[str, Any]) -> bool:
        """è¯„ä¼°æµ‹è¯•ç»“æœæ˜¯å¦ç¬¦åˆé¢„æœŸ"""
        summary = results["summary"]
        perf = results["performance"]
        
        # å®šä¹‰é€šè¿‡æ ‡å‡†
        criteria = {
            "error_rate": 0.05,  # é”™è¯¯ç‡ < 5%
            "idempotency_accuracy": 0.95,  # å¹‚ç­‰æ€§å‡†ç¡®ç‡ > 95%
            "avg_response_time": 2.0,  # å¹³å‡å“åº”æ—¶é—´ < 2s
            "p99_response_time": 5.0   # 99%å“åº”æ—¶é—´ < 5s
        }
        
        passed_checks = []
        failed_checks = []
        
        # æ£€æŸ¥é”™è¯¯ç‡
        if summary["error_rate"] <= criteria["error_rate"]:
            passed_checks.append(f"âœ… é”™è¯¯ç‡: {summary['error_rate']:.2%} <= {criteria['error_rate']:.1%}")
        else:
            failed_checks.append(f"âŒ é”™è¯¯ç‡: {summary['error_rate']:.2%} > {criteria['error_rate']:.1%}")
        
        # æ£€æŸ¥å¹‚ç­‰æ€§å‡†ç¡®ç‡
        if summary["idempotency_accuracy"] >= criteria["idempotency_accuracy"]:
            passed_checks.append(f"âœ… å¹‚ç­‰æ€§å‡†ç¡®ç‡: {summary['idempotency_accuracy']:.2%} >= {criteria['idempotency_accuracy']:.1%}")
        else:
            failed_checks.append(f"âŒ å¹‚ç­‰æ€§å‡†ç¡®ç‡: {summary['idempotency_accuracy']:.2%} < {criteria['idempotency_accuracy']:.1%}")
        
        # æ£€æŸ¥å“åº”æ—¶é—´
        if perf["avg_response_time"] <= criteria["avg_response_time"]:
            passed_checks.append(f"âœ… å¹³å‡å“åº”æ—¶é—´: {perf['avg_response_time']:.3f}s <= {criteria['avg_response_time']}s")
        else:
            failed_checks.append(f"âŒ å¹³å‡å“åº”æ—¶é—´: {perf['avg_response_time']:.3f}s > {criteria['avg_response_time']}s")
        
        if perf["p99_response_time"] <= criteria["p99_response_time"]:
            passed_checks.append(f"âœ… 99%å“åº”æ—¶é—´: {perf['p99_response_time']:.3f}s <= {criteria['p99_response_time']}s")
        else:
            failed_checks.append(f"âŒ 99%å“åº”æ—¶é—´: {perf['p99_response_time']:.3f}s > {criteria['p99_response_time']}s")
        
        print("\nğŸ” æµ‹è¯•ç»“æœè¯„ä¼°:")
        for check in passed_checks:
            print(f"  {check}")
        for check in failed_checks:
            print(f"  {check}")
        
        all_passed = len(failed_checks) == 0
        print(f"\n{'ğŸ‰ å‹åŠ›æµ‹è¯•é€šè¿‡!' if all_passed else 'âš ï¸ å‹åŠ›æµ‹è¯•æœªå®Œå…¨é€šè¿‡ï¼Œéœ€è¦å…³æ³¨ä»¥ä¸Šé—®é¢˜'}")
        
        return all_passed


def main():
    parser = argparse.ArgumentParser(description='å¹‚ç­‰æ€§å’Œç›‘æ§å‹åŠ›æµ‹è¯•å·¥å…·')
    parser.add_argument('--url', required=True, help='æœåŠ¡åŸºç¡€URL')
    parser.add_argument('--secret', default='test-secret', help='Webhookå¯†é’¥')
    parser.add_argument('--concurrent', type=int, default=50, help='å¹¶å‘è¯·æ±‚æ•°')
    parser.add_argument('--requests', type=int, default=1000, help='æ€»è¯·æ±‚æ•°')
    parser.add_argument('--duplicate-rate', type=float, default=0.3, help='é‡å¤è¯·æ±‚æ¯”ä¾‹')
    
    args = parser.parse_args()
    
    tester = IdempotencyMonitoringStressTester(args.url, args.secret)
    
    # æ›´æ–°æµ‹è¯•é…ç½®
    tester.test_config.update({
        "max_concurrent": args.concurrent,
        "total_requests": args.requests,
        "duplicate_rate": args.duplicate_rate
    })
    
    # è¿è¡Œæµ‹è¯•
    try:
        success = asyncio.run(tester.run_comprehensive_test())
        return 0 if success else 1
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        return 1


if __name__ == "__main__":
    exit(main()) 